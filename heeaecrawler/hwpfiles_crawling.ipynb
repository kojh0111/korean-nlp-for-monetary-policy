{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사록 hwp 파일 크롤링 (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "def get_hwp_data(startyear, startmonth, endyear, endmonth):\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    try:\n",
    "        while startyear <= endyear:\n",
    "            url = f'https://www.bok.or.kr/portal/singl/crncyPolicyDrcMtg/listYear.do?mtgSe=A&menuNo=200755&pYear={startyear}#content'\n",
    "            driver.get(url)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            tr_tags = driver.find_elements(By.CSS_SELECTOR, '#tableId > tbody > tr')\n",
    "            \n",
    "            for tr_tag in tr_tags:\n",
    "                day = tr_tag.find_element(By.CSS_SELECTOR,'th').text\n",
    "                month = int(day[:2])\n",
    "\n",
    "                if startyear == 2005 and month < startmonth:\n",
    "                    continue\n",
    "                if endyear == 2012 and month > endmonth:\n",
    "                    break\n",
    "\n",
    "                td_tag = tr_tag.find_elements(By.CSS_SELECTOR,'td')[2]\n",
    "                if startyear == 2006 or (startyear == 2007) & (month == 1):\n",
    "                    li_tag = td_tag.find_elements(By.CSS_SELECTOR,'div.fileGroupSet>div.fileGoupBox>ul>li')[1]\n",
    "                    a_tag = li_tag.find_element(By.CSS_SELECTOR,'a')\n",
    "                    dlink = a_tag.get_attribute('href')\n",
    "                else:\n",
    "                    a_tag = td_tag.find_element(By.CSS_SELECTOR,'div.fileGroupSet>div.fileGoupBox>ul>li>a')\n",
    "                    dlink = a_tag.get_attribute('href')\n",
    "\n",
    "                result.append(dict(\n",
    "                    year = startyear,\n",
    "                    day = day,\n",
    "                    dlink = dlink\n",
    "                ))\n",
    "\n",
    "            startyear += 1\n",
    "            \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return result\n",
    "\n",
    "def convert_to_datetime(df):\n",
    "    # 'day' 컬럼에서 \"월\"과 \"일\" 부분 제거\n",
    "    df['day'] = df['day'].str.replace('월', '').str.replace('일', '').str.split('(').str[0].str.strip()\n",
    "    \n",
    "    # 'year'와 'day'를 합쳐서 새로운 컬럼 'date' 생성\n",
    "    df['date'] = df['year'].astype(str) + ' ' + df['day']\n",
    "    \n",
    "    # 'date' 컬럼을 datetime 타입으로 변환\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y %m %d')\n",
    "    \n",
    "    # 'year'와 'day' 컬럼 제거\n",
    "    df = df.drop(columns=['year', 'day'])\n",
    "    \n",
    "    # 열 순서를 변경하여 'date'가 먼저 오도록 설정\n",
    "    df = df[['date', 'dlink']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = get_hwp_data(2005, 4, 2012, 12)\n",
    "df = pd.DataFrame(data, columns=['year', 'day', 'dlink'])\n",
    "\n",
    "df = convert_to_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다운로드 파일에 저장하기\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "for i in df['dlink']:\n",
    "    driver.get(i)\n",
    "\n",
    "time.sleep(20)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename 리스트 만들기\n",
    "\n",
    "import os\n",
    "\n",
    "path = \"C:/Users/kwkwo/Downloads/\"\n",
    "all_filenames = os.listdir(path)\n",
    "hwp_files = []\n",
    "\n",
    "for filename in all_filenames:\n",
    "    if filename[-4:] == \".hwp\":\n",
    "        hwp_files.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import olefile\n",
    "import zlib\n",
    "import struct\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 다운로드 폴더 경로 (Windows에서는 기본적으로 사용자 폴더에 있음)\n",
    "download_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    " \n",
    "# .hwp 파일 목록 가져오기\n",
    "hwp_files = [os.path.join(download_folder, f) for f in os.listdir(download_folder) if f.endswith('.hwp')]\n",
    "\n",
    "# '통화정책방향〉' ~ '(４) 심의결과' 사이의 내용만 가져오는 함수\n",
    "def extract_text_after_keyword(text):\n",
    "    start_keyword = \"통화정책방향〉\"\n",
    "    end_keyword = \"(４) 심의결과\"\n",
    "    \n",
    "    if start_keyword in text:\n",
    "        # '통화정책방향〉' 이후의 텍스트만 추출\n",
    "        extracted_text = text.split(start_keyword, 1)[1].strip()\n",
    "        \n",
    "        if end_keyword in extracted_text:\n",
    "            # '(４) 심의결과' 이전의 텍스트만 반환\n",
    "            extracted_text = extracted_text.split(end_keyword, 1)[0].strip()\n",
    "        \n",
    "        return extracted_text\n",
    "    \n",
    "    # 키워드가 없으면 빈 문자열 반환\n",
    "    return \"\"\n",
    "\n",
    "# '통화정책방향〉' 이전의 '0000년도 제00차 회의' 문자열을 가져오는 함수 <- title\n",
    "def extract_text_before_keyword(text):\n",
    "    keyword = \"통화정책방향〉\"\n",
    "    \n",
    "    if keyword in text:\n",
    "        # '통화정책방향〉' 이전의 텍스트만 추출\n",
    "        text_before_keyword = text.split(keyword, 1)[0]\n",
    "        \n",
    "        # 정규 표현식으로 '0000년도 제00차 회의' 패턴 찾기\n",
    "        match = re.search(r'\\d{4}년도 제\\d{1,2}차 회의', text_before_keyword)\n",
    "        \n",
    "        if match:\n",
    "            # 일치하는 패턴 반환\n",
    "            return match.group(0)\n",
    "    \n",
    "    # 패턴이 없으면 빈 문자열 반환\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_hwp_text(filename):\n",
    "    f = olefile.OleFileIO(filename)\n",
    "    dirs = f.listdir()\n",
    "    # print(dirs)\n",
    "\n",
    "    # HWP 파일 검증\n",
    "    if [\"FileHeader\"] not in dirs or \\\n",
    "            [\"\\x05HwpSummaryInformation\"] not in dirs:\n",
    "        raise Exception(\"Not Valid HWP.\")\n",
    "\n",
    "    # 문서 포맷 압축 여부 확인\n",
    "    header = f.openstream(\"FileHeader\")\n",
    "    header_data = header.read()\n",
    "    is_compressed = (header_data[36] & 1) == 1\n",
    "\n",
    "    # Body Sections 불러오기\n",
    "    nums = []\n",
    "    for d in dirs:\n",
    "        if d[0] == \"BodyText\":\n",
    "            nums.append(int(d[1][len(\"Section\"):]))\n",
    "    sections = [\"BodyText/Section\" + str(x) for x in sorted(nums)]\n",
    "\n",
    "    # 전체 text 추출\n",
    "    text = \"\"\n",
    "    for section in sections:\n",
    "        bodytext = f.openstream(section)\n",
    "        data = bodytext.read()\n",
    "        if is_compressed:\n",
    "            unpacked_data = zlib.decompress(data, -15)\n",
    "        else:\n",
    "            unpacked_data = data\n",
    "\n",
    "        # 각 Section 내 text 추출\n",
    "        section_text = \"\"\n",
    "        i = 0\n",
    "        size = len(unpacked_data)\n",
    "        while i < size:\n",
    "            header = struct.unpack_from(\"<I\", unpacked_data, i)[0]\n",
    "            rec_type = header & 0x3ff\n",
    "            rec_len = (header >> 20) & 0xfff\n",
    "\n",
    "            if rec_type in [67]:\n",
    "                rec_data = unpacked_data[i + 4:i + 4 + rec_len]\n",
    "                section_text += rec_data.decode('utf-16')\n",
    "                section_text += \"\\n\"\n",
    "\n",
    "            i += 4 + rec_len\n",
    "\n",
    "        text += section_text\n",
    "        text += \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# 리스트 초기화\n",
    "contents = []\n",
    "meeting_titles = []\n",
    "\n",
    "for hwp in hwp_files:\n",
    "    # print(hwp)\n",
    "    text = get_hwp_text(hwp)\n",
    "    contents.append(text)\n",
    "\n",
    "    # 첫 번째 '0000년도 제00차 회의' 형식의 문자열을 추출하여 리스트에 저장\n",
    "    title = extract_text_before_keyword(text)\n",
    "    if title:  # 만약 title이 None이 아닌 경우에만 추가\n",
    "        meeting_titles.append(title)\n",
    "\n",
    "# 텍스트 정제\n",
    "extracted_contents = [extract_text_after_keyword(text) for text in contents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = meeting_titles\n",
    "df['contents']=extracted_contents\n",
    "\n",
    "df = df[['date', 'title', 'dlink', 'contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df를 db에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "\n",
    "db = pymysql.connect(\n",
    "    host='paper-project-1.cne82okq8qfy.us-east-2.rds.amazonaws.com', \n",
    "    port=3306, \n",
    "    user=\"heeae\", \n",
    "    passwd=\"0000\", \n",
    "    db=\"PAPER_PROJECT\", \n",
    "    charset=\"utf8\"\n",
    ")\n",
    "\n",
    "cursor = db.cursor()\n",
    "\n",
    "#SQL에 데이터 넣기 (수정: json 키 \"content\" > \"keyword\")\n",
    "sql = \"INSERT INTO text_analysis (document_type, date, title, sentences) VALUES (%s, %s, %s, %s);\"\n",
    "for i, row in df.iterrows():\n",
    "    sentences_json = json.dumps({\"keyword\": row[\"contents\"]})\n",
    "    cursor.execute(sql, ('mpc_minutes', row[\"date\"], row[\"title\"], sentences_json))\n",
    "  \n",
    " \n",
    "db.commit() \n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences 행 {'keyword':\"파일 단위 text\"} > {'keyword':[[문장1],[문장2],...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymysql\n",
    "\n",
    "# 데이터베이스에 연결\n",
    "db = pymysql.connect(\n",
    "    host='paper-project-1.cne82okq8qfy.us-east-2.rds.amazonaws.com', \n",
    "    port=3306, \n",
    "    user=\"heeae\", \n",
    "    passwd=\"0000\", \n",
    "    db=\"PAPER_PROJECT\", \n",
    "    charset=\"utf8\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "# 테이블에서 데이터를 선택\n",
    "sql = \"SELECT id, sentences from text_analysis WHERE document_type = 'mpc_minutes';\"\n",
    "cursor.execute(sql)\n",
    "records = cursor.fetchall()\n",
    "\n",
    "for record in records:\n",
    "    # id와 현재 JSON 데이터를 추출\n",
    "    record_id = record[0]\n",
    "    current_json = record[1]\n",
    "    \n",
    "    # 현재 JSON 데이터를 로드\n",
    "    data = json.loads(current_json)\n",
    "    \n",
    "    # 'content'를 문장으로 나누고 2차원 리스트로 변환\n",
    "    sentences = data['keyword'].split('\\r\\n')\n",
    "    sents_as_listlist = [[sent] for sent in sentences]\n",
    "\n",
    "    # 변환된 2차원 리스트를 content에 업데이트\n",
    "    data['keyword'] = sents_as_listlist\n",
    "\n",
    "    # 업데이트된 딕셔너리를 JSON 문자열로 변환\n",
    "    updated_json = json.dumps(data)\n",
    "    \n",
    "    # 변환된 JSON 문자열을 데이터베이스에 업데이트\n",
    "    update_sql = \"UPDATE text_analysis SET sentences = %s WHERE id = %s\"\n",
    "    cursor.execute(update_sql, (updated_json, record_id))\n",
    "\n",
    "# 데이터베이스에 변경 사항을 커밋\n",
    "db.commit()\n",
    "\n",
    "# 커서와 데이터베이스 연결 종료\n",
    "cursor.close()\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
